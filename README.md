## 🧑‍💻 Codecademy Data Engineering Project 

---
### 📖 General overview
This repository contains a project created as part of the **Codecademy Data Engineering Career Path**.  
It is intended for **educational purposes only** and demonstrates concepts learned during the course.

---

### 📝 Purpose
The goal of this project is to **practice and apply data engineering skills**, including:

- Data extraction, transformation, and loading (**ETL**)
- Working with **databases and SQL**
- Data analysis and processing using **Python**
- Building **data pipelines**
- Environment **containerization**

---

### ⚠️ Disclaimer
This project is **not intended for production use**.  
All datasets and examples are for **learning and practice purposes only**.

---

### 🛠️ Technologies used, architecture and development workflow
- Docker
- Python
- PostgreSQL  
- VS Code
- Jupyter Notebook  

![Architecture diagram](images/data_pipeline_placeholder.png)

> **Note:** Replace `data_pipeline_placeholder.png` with your actual diagram file in the `images` folder.


The project was developed on a local **VS Code** installation that used **docker containers** to host the **jupyter kernel** for python and a **PostgreSQL** database.

![Development workflow](images/data_pipeline_placeholder.png)

> **Note:** Replace `data_pipeline_placeholder.png` with your actual diagram file in the `images` folder.

---

### 📂 Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/your-repo.git
   cd your-repo
   ```

### 🪧 Usage


1. Run Jupyter notebooks: Open the notebooks provided in the repository to explore datasets, analyze data, and run queries.

2. Connect to PostgreSQL database: Use your preferred client (DBeaver, pgAdmin, or Python scripts) to connect to the database and interact with the tables.

3. Experiment with ETL scripts: Modify or run the ETL pipelines included to practice transforming and loading data.


### 👤 Author

[Your Name]

Educational project for Codecademy Data Engineering Career Path